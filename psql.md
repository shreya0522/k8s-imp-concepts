# 1- What if you want to migrate your on premise psql cluster to on premise ? 
 **Two major PostgreSQL migration workflows** from cloud to on-premise, along with **real-world examples and key decision points**.

---

## üß≠ WORKFLOW 1: **Logical Backup and Restore using `pg_dump` + `pg_restore`**

### üî∏ Best For:

* Migrating individual databases
* Cross-version migration (e.g. PostgreSQL 13 ‚Üí 15)
* Smaller to medium-sized datasets
* One-time export/import (not replication)

---

### ‚úÖ **Step-by-Step Workflow**

| Step | Action                              | Command or Description                               |
| ---- | ----------------------------------- | ---------------------------------------------------- |
| 1Ô∏è‚É£  | Connect to cloud DB and export dump | `pg_dump -h cloud-host -U user -Fc mydb > mydb.dump` |
| 2Ô∏è‚É£  | Transfer dump to on-prem server     | `scp mydb.dump user@onprem:/path/`                   |
| 3Ô∏è‚É£  | Create database on-prem             | `createdb -U user mydb`                              |
| 4Ô∏è‚É£  | Restore dump                        | `pg_restore -U user -d mydb /path/mydb.dump`         |
| 5Ô∏è‚É£  | Validate data                       | Check table counts, sample records, indexes          |

---

### üì¶ Example

```bash
# Cloud
pg_dump -h prod-db.cloudpg.com -U postgres -Fc tt_app > tt_app.dump

# On-prem
scp tt_app.dump user@onprem-server:/tmp/
createdb -U postgres tt_app
pg_restore -U postgres -d tt_app /tmp/tt_app.dump
```

---

### ‚ö†Ô∏è Limitations

* Requires full downtime for consistent dump
* No users/roles unless explicitly dumped (`--create --role`)
* No replication or WAL logs
* No PITR (point-in-time recovery)

---

### ‚úÖ Pros

* Simple and portable
* Works across versions/platforms
* Easy to automate in scripts/CI

---

## üß≠ WORKFLOW 2: **Physical Migration using `pg_basebackup` + WAL logs**

### üî∏ Best For:

* Full **cluster migration** (including all DBs, roles, configs)
* Need for **PITR** or **replica** setup
* Migrating **large databases** with minimal downtime
* Setting up **standbys** or **failover nodes**

---

### ‚úÖ **Step-by-Step Workflow**

| Step | Action                                  | Command or Description                                                         |
| ---- | --------------------------------------- | ------------------------------------------------------------------------------ |
| 1Ô∏è‚É£  | Enable WAL archiving on cloud DB        | In `postgresql.conf`: `archive_mode=on`, `archive_command='cp %p /archive/%f'` |
| 2Ô∏è‚É£  | Take base backup                        | `pg_basebackup -h cloud -U replica_user -D /base -Fp -Xs`                      |
| 3Ô∏è‚É£  | Stop cloud DB (optional for final sync) | To freeze writes temporarily                                                   |
| 4Ô∏è‚É£  | Copy all base + WAL to on-prem          | `rsync -av /base /archive user@onprem:/pgdata`                                 |
| 5Ô∏è‚É£  | On on-prem, configure recovery          | Add `restore_command`, create `standby.signal`                                 |
| 6Ô∏è‚É£  | Start on-prem PostgreSQL                | WALs will be replayed to reach consistent state                                |

---

### üì¶ Example

```bash
# Cloud side: base backup
pg_basebackup -h prod-db.cloudpg.com -U replica -D /tmp/backup -Fp -Xs

# Transfer to on-prem
rsync -av /tmp/backup user@onprem:/pgdata
rsync -av /cloud/wal_archive user@onprem:/pg_wal_archive

# On-prem: recovery config
echo "restore_command = 'cp /pg_wal_archive/%f %p'" >> postgresql.conf
touch /pgdata/standby.signal

# Start DB
sudo systemctl start postgresql
```

---

### ‚ö†Ô∏è Limitations

* More complex
* Must match PostgreSQL version exactly
* Can't migrate across OS/arch (e.g. Windows ‚Üí Linux)

---

### ‚úÖ Pros

* WAL-level consistency guaranteed
* Supports streaming, PITR, replication
* Faster for large datasets
* Includes users, multiple DBs, internal configs

---

## üîç Workflow Comparison Table

| Feature                         | `pg_dump` + `pg_restore` | `pg_basebackup` + WAL  |
| ------------------------------- | ------------------------ | ---------------------- |
| Granular DB migration           | ‚úÖ                        | ‚ùå (entire cluster)     |
| Cross-version migration         | ‚úÖ                        | ‚ùå (same major version) |
| Users/Roles                     | ‚ùå (manual)               | ‚úÖ                      |
| Extensions/Configs              | ‚ùå (manual)               | ‚úÖ                      |
| PITR / Streaming Replication    | ‚ùå                        | ‚úÖ                      |
| Disk space / time for large DBs | Slower                   | Faster                 |
| Simplicity                      | ‚úÖ                        | ‚ùå                      |
| Ideal for                       | < 100GB / simple cases   | TB-scale / replicas    |

---

## üßæ Final Interview-Ready Answer:

> **"There are two ways I‚Äôd approach PostgreSQL cloud-to-on-prem migration. For simple use cases, I‚Äôd use `pg_dump` and `pg_restore` to export and import the database. It‚Äôs easy, cross-version compatible, and good for smaller databases. But for full cluster-level consistency, including roles and WAL-based replay, I‚Äôd use `pg_basebackup` with archived WAL logs, then replay those logs on the on-prem node to reach a consistent state ‚Äî especially useful for large, live systems or when replication is needed."**

---

Let me know if you want a visual diagram for this or an Ansible playbook to automate either path.

-

[1]: https://www.enterprisedb.com/postgresql-database-backup-recovery-what-works-wal-pitr?utm_source=chatgpt.com "A Complete Guide to PostgreSQL Backup & Recovery - EDB"
[2]: https://www.postgresql.org/docs/current/continuous-archiving.html?utm_source=chatgpt.com "17: 25.3. Continuous Archiving and Point-in-Time Recovery (PITR)"
[3]: https://moldstud.com/articles/p-essential-backup-strategies-for-remote-postgresql-developers-best-practices?utm_source=chatgpt.com "Essential Backup Strategies for Remote PostgreSQL Developers"
[4]: https://stackoverflow.com/questions/79452398/whats-the-best-practice-for-postgresql-database-migration-between-on-premise-se?utm_source=chatgpt.com "What's the best practice for PostgreSQL database migration ..."
[5]: https://aws.amazon.com/blogs/database/best-practices-for-migrating-postgresql-databases-to-amazon-rds-and-amazon-aurora/?utm_source=chatgpt.com "Best practices for migrating PostgreSQL databases to Amazon RDS ..."
[6]: https://docs.ionos.com/cloud/databases/postgresql/overview/backup-recovery-and-migration?utm_source=chatgpt.com "Backup and Recovery | Products - IONOS Cloud Documentation"
[7]: https://docs.aws.amazon.com/prescriptive-guidance/latest/migration-databases-postgresql-ec2/streaming-replication-consideration.html?utm_source=chatgpt.com "Streaming replication - AWS Prescriptive Guidance"

# =============================================================================================================================


# 2. What each PostgreSQL utility actually does under the hood

| Utility         | Purpose                                             | What really happens internally                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        | Typical use-case                                                                                            |
| --------------- | --------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------- |
| `pg_dump`       | **Logical export** of one database (schema + data)  | 1. Connects through libpq as a normal client.<br>2. Starts a **serializable‚Äêsnapshot transaction** so every row it reads is consistent.<br>3. Queries the system catalogs to reconstruct DDL (tables, indexes, FK-chains, privileges, extensions, ‚Ä¶).<br>4. Extracts rows with `COPY ... TO STDOUT`, writing them to the dump file.<br>5. Can emit **plain SQL**, **custom** (`-Fc`), or **directory** format.<br>6. No WAL data is copied; it is a pure logical description of objects and rows.                                                                                                     | Version upgrades, cross-platform moves, object-level restores, small/medium DBs.                            |
| `pg_basebackup` | **Physical, binary snapshot** of an entire cluster  | 1. Uses the **replication protocol** over the same port (requires a role with `REPLICATION` privilege).<br>2. Calls `pg_start_backup()` implicitly in the server, which forces a checkpoint and starts writing special *backup label* WAL records.<br>3. Streams every data-file block (8 kB at a time) to the client.<br>4. Option `-Xs/-Xf` also **streams WAL** so the snapshot can replay up to a consistent end-of-backup record.<br>5. Calls `pg_stop_backup()`, server writes an ‚Äúend of backup‚Äù WAL record ‚Üí the resulting directory tree is byte-for-byte identical to `PGDATA` at that LSN. | Building new physical stand-bys, full-cluster migrations, large datasets, zero-loss fail-over preparations. |
| `pg_restore`    | **Re-hydrate** a `pg_dump` made with `-Fc` or `-Fd` | 1. Reads the dump‚Äôs **TOC** (table-of-contents).<br>2. Recreates databases/schemas/roles if they were dumped with `--create`.<br>3. Runs DDL in dependency order.<br>4. Uses `COPY ... FROM STDIN` to load each table, optionally **in parallel** (`-j`).<br>5. Re-creates indexes, constraints, sequences, statistics, comments, privileges.                                                                                                                                                                                                                                                         | Loading a logical dump onto a fresh cluster or performing object-level point-in-time restores.              |

---

### 2. What exactly is WAL?

*Write-Ahead Logging* (files stored in `$PGDATA/pg_wal`, previously `pg_xlog`) is a **sequential byte-stream of change records**:

* A record is appended **before** the actual data page is flushed (hence ‚Äúwrite-ahead‚Äù).
* Each record has an LSN (Log Sequence Number).
* On crash-recovery PostgreSQL replays WAL to bring data files back to a consistent state.
* WAL records contain enough info to **re-create, redo or undo** every change to the data pages.

---

### 3. How replicas use WAL

1. **Physical (streaming) replication**

   * `pg_basebackup` seeds the standby.
   * The primary sends **raw WAL records** over the `walreceiver/walsender` process pair.
   * The standby re-plays them byte-for-byte ‚Üí it is an exact binary copy of the primary (same OIDs, same block layout).
   * Pros: fast, minimal CPU, supports synchronous or async modes.
   * Cons: same major version, cannot filter tables, cannot be used for cross-platform moves.

2. **Logical replication / decoding**

   * WAL is **decoded** by `logical decoding` into high-level messages (`INSERT/UPDATE/DELETE`).
   * These messages are published on a **replication slot**; subscribers apply them with normal SQL.
   * Pros: choose specific tables/columns, replicate between different major versions, even different architectures.
   * Cons: a bit slower, sequences are handled separately, DDL replication is manual, requires PK/replica identity.

---

### 4. Putting it all together ‚Äî choosing the right tool

| Criterion               | Use `pg_dump / pg_restore` (logical)                                          | Use `pg_basebackup + WAL` (physical)                              |
| ----------------------- | ----------------------------------------------------------------------------- | ----------------------------------------------------------------- |
| **Granularity**         | Single DB or selected schemas                                                 | Whole cluster only                                                |
| **Cross-version/OS**    | Yes (13 ‚Üí 16, ARM ‚Üí x86)                                                      | No (must match major ver & architecture)                          |
| **Size / speed**        | Slower for TBs, creates large dump files                                      | Streams blocks directly, faster for big data                      |
| **Downtime**            | Requires a consistent snapshot ‚áí usually downtime or `--snapshot` on replicas | Can be near-zero downtime (keep primary running, promote standby) |
| **Need PITR / standby** | Not possible                                                                  | Fully supported via WAL replay                                    |
| **Typical uses**        | Upgrades, selective restores, dev refresh                                     | HA replicas, large migrations, disaster recovery                  |

---

### 5. Practical interview-sized explanation

> *‚Äú`pg_dump` gives me a logical copy ‚Äî it walks the catalogs, pulls a consistent snapshot of rows with COPY, and writes pure SQL (or a custom archive) that can be replayed anywhere.
> `pg_basebackup` is different: it‚Äôs a binary copy of the entire `PGDATA` plus the WAL stream that started at the checkpoint and ends at `pg_stop_backup()`.
> WAL itself is PostgreSQL‚Äôs change journal. Physical replicas just re-apply those raw WAL records, giving a byte-identical copy; logical replication first decodes WAL into SQL-level changes so you can pick specific tables or even replicate across major versions.‚Äù*

Armed with that 30-second summary (and the deeper details above) you can cover *what each utility does, what WAL is, and how logical vs. physical replication differ* ‚Äî exactly what an interviewer is probing for.

# ==========================================================================================================

# 3. Is WAL log in psql is similar to bin log in mysql 

Yes ‚Äî you're right! In **MySQL**, the equivalent of PostgreSQL's WAL is the **binary log (binlog)**.

Let‚Äôs break it down the same way ‚Äî how **MySQL handles logical + physical backups**, how **binlog-based replication/migration works**, and how to do **single DB vs full-cluster migration**.

---

## ‚úÖ WAL in PostgreSQL ‚âà Binlog in MySQL

| Concept                | PostgreSQL     | MySQL                                    |
| ---------------------- | -------------- | ---------------------------------------- |
| Write-Ahead Logging    | WAL (`pg_wal`) | Binary Log (`binlog`)                    |
| Physical replication   | WAL streaming  | Binlog-based replication                 |
| Logical replication    | WAL decoding   | Row/statement-based binlog + replication |
| Point-in-time recovery | WAL replay     | Binlog replay                            |

---

## üß≠ MySQL Migration Workflows

---

### 1Ô∏è‚É£ **Single DB Migration (Logical)** ‚Äî via `mysqldump`

#### ‚úÖ Workflow:

| Step                 | Command                                            |
| -------------------- | -------------------------------------------------- |
| Dump single DB       | `mysqldump -u root -p --databases mydb > mydb.sql` |
| Transfer to new host | `scp mydb.sql user@onprem:/tmp/`                   |
| Restore              | `mysql -u root -p < /tmp/mydb.sql`                 |

#### ‚úÖ Pros:

* Cross-version & cross-platform
* Selective (only one DB)
* Human-readable

#### ‚ùå Cons:

* Slower for large datasets
* No binlog info, can't do PITR
* Doesn't preserve user grants unless added explicitly

---

### 2Ô∏è‚É£ **Full Cluster Migration (Logical)** ‚Äî `mysqldump` or `mysqlpump`

```bash
mysqldump -u root -p --all-databases --routines --events --triggers > all.sql
```

* Includes all DBs + objects (triggers, stored procs, etc.)
* Restore via: `mysql < all.sql`

---

### 3Ô∏è‚É£ **Physical Backup with Binlogs for PITR**

#### Tools:

* `mysqlbackup` (MySQL Enterprise Backup) or
* `xtrabackup` (Percona, for open source)

#### ‚úÖ Workflow:

| Step | Description                                                  |
| ---- | ------------------------------------------------------------ |
| 1Ô∏è‚É£  | Take physical backup (cold or hot) using `xtrabackup`        |
| 2Ô∏è‚É£  | Also backup `binlog` files (e.g., `/var/lib/mysql/binlog.*`) |
| 3Ô∏è‚É£  | Restore backup on on-prem                                    |
| 4Ô∏è‚É£  | Replay binlogs for PITR using `mysqlbinlog`                  |

```bash
mysqlbinlog --start-datetime="2025-06-20 10:00:00" binlog.000123 | mysql -u root -p
```

---

### 4Ô∏è‚É£ **Real-Time Replication from Cloud to On-Prem**

This is similar to PostgreSQL streaming replication.

#### ‚úÖ Steps:

1. **Enable binlog on source (cloud)**
   Set in `my.cnf`:

   ```ini
   server-id=1
   log-bin=mysql-bin
   binlog_format=row
   ```

2. **Create replication user** on cloud:

   ```sql
   GRANT REPLICATION SLAVE ON *.* TO 'repl'@'%' IDENTIFIED BY 'replpass';
   ```

3. **On on-prem target**, configure as replica:

   ```sql
   CHANGE MASTER TO
     MASTER_HOST='cloud-host',
     MASTER_USER='repl',
     MASTER_PASSWORD='replpass',
     MASTER_LOG_FILE='mysql-bin.000001',
     MASTER_LOG_POS=154;
   START SLAVE;
   ```

4. Use `SHOW SLAVE STATUS\G` to monitor.

---

## üì¶ Physical vs Logical in MySQL

| Feature            | Logical (`mysqldump`) | Physical (`xtrabackup`, `mysqlbackup`) |
| ------------------ | --------------------- | -------------------------------------- |
| Cross-platform     | ‚úÖ Yes                 | ‚ùå No (must match OS/FS/arch)           |
| Cross-version      | ‚úÖ Yes                 | ‚ö†Ô∏è Only minor versions                 |
| Binary logs needed | ‚ùå                     | ‚úÖ Yes (for PITR)                       |
| Select DB/tables   | ‚úÖ                     | ‚ùå Only full cluster                    |
| Speed              | ‚ùå Slower              | ‚úÖ Faster (block-level)                 |

---

## ‚úÖ Interview-Ready Summary:

> **"In MySQL, the equivalent of PostgreSQL WAL is the binary log or binlog. For single DB migrations, I‚Äôd use `mysqldump` or `mysqlpump` for logical export. For full-cluster or PITR scenarios, I‚Äôd combine physical backup (like Percona XtraBackup) with archived binlogs. For real-time replication or cloud-to-on-prem sync, I‚Äôd set up binlog-based replication by configuring the on-prem server as a replica."**

# =================================================================================================================

# 4. Physical and logical replication acc to aws doc 

Great question. Let's break down that paragraph **phrase by phrase**, so you fully understand what **logical replication** means in PostgreSQL ‚Äî especially compared to physical replication.

---

### üîç Full Breakdown of the Statement:

#### üìå **"Logical replication is a method of replicating data objects and their changes based upon their replication identity."**

* **Logical replication** means replicating **rows, tables, and SQL-level changes**, not raw files or blocks.
* **Replication identity**: this refers to the primary key (or unique key) that PostgreSQL uses to identify rows for replication (`REPLICA IDENTITY`).

  * Example: If a table doesn‚Äôt have a primary key, updates can‚Äôt be replicated correctly unless you set a `REPLICA IDENTITY FULL`.

---

#### üìå **"We use the term logical in contrast to physical replication, which uses exact block addresses and byte-by-byte replication."**

* **Logical**: operates on SQL-level changes like `INSERT`, `UPDATE`, `DELETE`.
* **Physical**: replicates the **entire data directory** block-by-block (like cloning the disk).

  * Requires same OS, same PostgreSQL version, same file layout.

---

#### üìå **"Logical replication uses a publisher and subscriber model with one or more subscribers subscribing to one or more publications on the publisher node."**

* Think of **publications** like a ‚Äúchannel‚Äù the source database creates ‚Äî a list of tables to replicate.
* **Publisher**: the source database (cloud, master, etc.)
* **Subscriber**: the target database (on-prem, replica, etc.)

  ```sql
  -- Publisher
  CREATE PUBLICATION mypub FOR TABLE orders, users;

  -- Subscriber
  CREATE SUBSCRIPTION mysub
    CONNECTION 'host=publisher_host dbname=app user=repl password=xyz'
    PUBLICATION mypub;
  ```

---

#### üìå **"Subscribers pull data from the publications they subscribe to and may subsequently republish data to allow cascading replication or more complex configurations."**

* Replication is **pull-based** ‚Äî subscriber contacts publisher to sync changes.
* A subscriber can also **become a publisher**, enabling **cascading replication** (A ‚Üí B ‚Üí C).

---

#### üìå **"Unlike physical replication, you can set up logical replication between two different major versions of PostgreSQL."**

* **Huge advantage**: You can replicate from PostgreSQL 13 ‚Üí 15, for example.
* Useful in **zero-downtime upgrades** or **heterogeneous setups**.
* In contrast, physical replication (e.g. streaming replica) **requires exact version match**.

---

### ‚úÖ Summary: What It Really Means

| Logical Replication                                | Physical Replication                             |
| -------------------------------------------------- | ------------------------------------------------ |
| SQL-level changes (row-level `INSERT/UPDATE`)      | Binary-level block replication (filesystem sync) |
| Works across major versions (13 ‚Üí 15)              | Same major version required                      |
| Table-level granularity                            | Whole cluster                                    |
| Pull-based (subscriber initiates sync)             | Push-based (primary writes to standby)           |
| Supports cascading, filtering, partial replication | No filtering; full copy                          |
| More flexible for cloud ‚Üí on-prem + upgrades       | Simpler, faster for large clusters and HA setups |

---

If you're in an interview and get asked about this, you can say:

> **"Logical replication replicates actual SQL changes like inserts or updates at the table level, and is more flexible ‚Äî you can replicate specific tables or even across PostgreSQL major versions. It uses a publisher-subscriber model, unlike physical replication which does a binary copy of the entire cluster. Logical is great for upgrades or selective sync; physical is better for full HA replicas."**


`
---

````
               PostgreSQL Replication Comparison
               ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

                   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                   ‚îÇ   Publisher  ‚îÇ
                   ‚îÇ   (Primary)  ‚îÇ
                   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚îÇ
       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
       ‚îÇ                                       ‚îÇ
       ‚ñº                                       ‚ñº

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Logical Replication  ‚îÇ          ‚îÇ  Physical Replication  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Model:                         |    Model:
 Publisher/Subscriber          |    Primary/Standby

Data Replicated:               |    Data Replicated:
 Table-level rows              |    Whole database files (byte-level)

Replication Mechanism:         |    Replication Mechanism:
 Decoded WAL (INSERT/UPDATE)   |    Raw WAL + file-level streaming

Version Compatibility:         |    Version Compatibility:
 Across PostgreSQL versions    |    Exact same major version only

Flexibility:                   |    Flexibility:
 Select tables, columns        |    No filtering ‚Äì full replica only

Direction:                     |    Direction:
 Pull (subscriber pulls data)  |    Push (primary sends WAL stream)

Writable Replica:              |    Writable Replica:
 Yes (on non-replicated tables)|    No (read-only standby)

Use Cases:                     |    Use Cases:
 - Selective replication       |    - HA standby
 - Zero-downtime upgrades      |    - PITR setups
 - Cross-region sync           |    - DR failover clusters
````

---

### üß† How to Remember:

| Term     | Think‚Ä¶                                |
| -------- | ------------------------------------- |
| Logical  | Flexible, SQL-level, upgrade-friendly |
| Physical | Exact copy, fast, strict version lock |

Let me know if you want a cheat sheet or markdown version for your notes!
